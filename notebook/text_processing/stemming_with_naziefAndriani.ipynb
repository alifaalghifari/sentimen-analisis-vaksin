{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>location</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-11 23:58:25+00:00</td>\n",
       "      <td>Bustam, ketua PWI Papua Barat, mengajak para w...</td>\n",
       "      <td>ywfbruh</td>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "      <td>['OtsusPapuaTerbaik']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-11 23:56:03+00:00</td>\n",
       "      <td>Vaksinasi Diklaim Tingkatkan Jumlah Pengunjung...</td>\n",
       "      <td>Harian_Jogja</td>\n",
       "      <td>Yogyakarta, Indonesia</td>\n",
       "      <td>['beritajogja', 'jogja', 'jogjaistimewa']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-11 23:40:03+00:00</td>\n",
       "      <td>Wujudkan kekebalan komunal setelah vaksinasi d...</td>\n",
       "      <td>polres_pemalang</td>\n",
       "      <td>Pemalang, Indonesia</td>\n",
       "      <td>['polriindonesia', 'polriuntukindonesia', 'kab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-11 23:38:51+00:00</td>\n",
       "      <td>Terima kasih kepada pemerintah atas perhatiann...</td>\n",
       "      <td>TomtomTheTITANS</td>\n",
       "      <td>bandung - jakarta</td>\n",
       "      <td>['VaksinUntukKita']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-11 23:36:44+00:00</td>\n",
       "      <td>NU Jatim: Jangan Ikutin Hoaks, Vaksin Sinovac ...</td>\n",
       "      <td>BacaDiBaBe</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>['MengenalVaksinAstraZeneca', 'PenerimaVaksinC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime  \\\n",
       "0  2021-03-11 23:58:25+00:00   \n",
       "1  2021-03-11 23:56:03+00:00   \n",
       "2  2021-03-11 23:40:03+00:00   \n",
       "3  2021-03-11 23:38:51+00:00   \n",
       "4  2021-03-11 23:36:44+00:00   \n",
       "\n",
       "                                                Text         Username  \\\n",
       "0  Bustam, ketua PWI Papua Barat, mengajak para w...          ywfbruh   \n",
       "1  Vaksinasi Diklaim Tingkatkan Jumlah Pengunjung...     Harian_Jogja   \n",
       "2  Wujudkan kekebalan komunal setelah vaksinasi d...  polres_pemalang   \n",
       "3  Terima kasih kepada pemerintah atas perhatiann...  TomtomTheTITANS   \n",
       "4  NU Jatim: Jangan Ikutin Hoaks, Vaksin Sinovac ...       BacaDiBaBe   \n",
       "\n",
       "                location                                           hashtags  \n",
       "0      Pennsylvania, USA                              ['OtsusPapuaTerbaik']  \n",
       "1  Yogyakarta, Indonesia          ['beritajogja', 'jogja', 'jogjaistimewa']  \n",
       "2    Pemalang, Indonesia  ['polriindonesia', 'polriuntukindonesia', 'kab...  \n",
       "3      bandung - jakarta                                ['VaksinUntukKita']  \n",
       "4              Indonesia  ['MengenalVaksinAstraZeneca', 'PenerimaVaksinC...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data['Text']\n",
    "data_copy = data[['Datetime','Username','location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Bustam, ketua PWI Papua Barat, mengajak para w...\n",
       "1       Vaksinasi Diklaim Tingkatkan Jumlah Pengunjung...\n",
       "2       Wujudkan kekebalan komunal setelah vaksinasi d...\n",
       "3       Terima kasih kepada pemerintah atas perhatiann...\n",
       "4       NU Jatim: Jangan Ikutin Hoaks, Vaksin Sinovac ...\n",
       "                              ...                        \n",
       "7002    Lindungi Anak Dari Covid-19 Dengan Vaksinasi \\...\n",
       "7003    13.Kanwil Kemenkumham Sumsel: Vaksinasi tetap ...\n",
       "7004    Ini Capaian Vaksin di SD Negeri 014 Kota Bangu...\n",
       "7005    Vaksinasi tujuannya untuk melindungi anak dari...\n",
       "7006    Dikasih info lagi maszzeh ... Yuk ikuti vaksin...\n",
       "Name: Text, Length: 7007, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Username</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-11 23:58:25+00:00</td>\n",
       "      <td>ywfbruh</td>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-11 23:56:03+00:00</td>\n",
       "      <td>Harian_Jogja</td>\n",
       "      <td>Yogyakarta, Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-11 23:40:03+00:00</td>\n",
       "      <td>polres_pemalang</td>\n",
       "      <td>Pemalang, Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-11 23:38:51+00:00</td>\n",
       "      <td>TomtomTheTITANS</td>\n",
       "      <td>bandung - jakarta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-11 23:36:44+00:00</td>\n",
       "      <td>BacaDiBaBe</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime         Username               location\n",
       "0  2021-03-11 23:58:25+00:00          ywfbruh      Pennsylvania, USA\n",
       "1  2021-03-11 23:56:03+00:00     Harian_Jogja  Yogyakarta, Indonesia\n",
       "2  2021-03-11 23:40:03+00:00  polres_pemalang    Pemalang, Indonesia\n",
       "3  2021-03-11 23:38:51+00:00  TomtomTheTITANS      bandung - jakarta\n",
       "4  2021-03-11 23:36:44+00:00       BacaDiBaBe              Indonesia"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(input):\n",
    "  input = input.replace(\".\", \"\")\n",
    "  input = input.replace(\",\", \"\")\n",
    "  input = input.replace(\":\", \"\")\n",
    "  input = input.replace(\"-\", \" \")\n",
    "  input = input.replace(\"?\", \"\")\n",
    "  input = input.replace(\"!\", \"\")\n",
    "  input = input.replace(\"(\", \"\")\n",
    "  input = input.replace(\")\", \"\")\n",
    "  input = input.replace(\"[\", \"\")\n",
    "  input = input.replace(\"]\", \"\")\n",
    "  input = input.replace(\"{\", \"\")\n",
    "  input = input.replace(\"}\", \"\")\n",
    "  input = input.replace(\"'\", \"\")\n",
    "  input = input.replace('\"', \"\")\n",
    "  input = input.replace(\"/\", \"\")\n",
    "  input = input.replace(\"\\n\", \" \")\n",
    "  return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(words):\n",
    "  \n",
    "  return words.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open stopword\n",
    "\n",
    "def stop_word(word):\n",
    "\n",
    "  f = open('../components/id.stopwords.02.01.2016.txt')\n",
    "  s_word = f.read()\n",
    "\n",
    "  if word not in s_word :\n",
    "    return word\n",
    "  \n",
    "\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kamus bahasa indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "kamus_clean = []\n",
    "\n",
    "with open('../components/kata-dasar-indonesia.txt') as f:\n",
    "  kamus = f.read()\n",
    "  kamus = kamus.split(' ')\n",
    "\n",
    "  for w in kamus:\n",
    "  \n",
    "    rx = re.findall(r'[^\\n]+$', w)\n",
    "\n",
    "    kamus_clean.append(rx[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKAR_KATA = []\n",
    "\n",
    "def kamus_word(word):\n",
    "    checked = False\n",
    "    # kamus = map(clean_word, kamus)\n",
    "    if word in kamus_clean:\n",
    "      checked = True\n",
    "      # AKAR_KATA.append(word)\n",
    "      return checked, word \n",
    "    return checked, word\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func for delete infleksional suffiks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hapus_infleksional_suffiks(word):\n",
    "  # akhiran -lah, -kah, -nya, -tah, -pun\n",
    "  checked = False\n",
    "  \n",
    "  \n",
    "  if word.endswith('lah') or word.endswith('kah') or word.endswith('nya') or word.endswith('tah') or word.endswith('pun'):\n",
    "    word = word[0 : len(word) - 3]\n",
    "    \n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(word)\n",
    " \n",
    "    return checked, word\n",
    "\n",
    "  # akhiran -ku, -mu\n",
    "  elif word.endswith('ku') or word.endswith('mu'):\n",
    "    word = word[0 : len(word) - 2]\n",
    "\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(word)\n",
    "    return checked, word\n",
    "    \n",
    "  return checked, word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func for derivation suffiks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hapus_derivation_suffiks(word):\n",
    "  checked = False\n",
    "    # akhiran kan\n",
    "  if word.endswith('kan') and len(word) > 4:\n",
    "    word = word[0 : len(word) - 3]\n",
    "\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(word)\n",
    "    return checked, word\n",
    "\n",
    "  # akhiran i\n",
    "  if word.endswith('i') and len(word) > 3:\n",
    "    word = word[0 : len(word) - 1]\n",
    "\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(word)\n",
    "    return checked, word\n",
    "\n",
    "  # akhiran an\n",
    "  if word.endswith('an') and len(word) > 4:\n",
    "    word = word[0 : len(word) - 2]\n",
    "\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(word)\n",
    "    return checked, word\n",
    "\n",
    "\n",
    "  return checked, word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func for delete derivation prefiks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hapus_derivation_prefiks(word):\n",
    "  checked = False\n",
    "  # awalan mempel-\n",
    "  if (word.startswith('mempel')) and (len(word) > 6):\n",
    "    sub_word = word[6:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "    if checked==False:    \n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "      return checked, word\n",
    "      \n",
    "    return checked, word\n",
    "  \n",
    "  # awalan memper-\n",
    "  if (word.startswith('memper')) and (len(word) > 6):\n",
    "    sub_word = word[6:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "    if checked==False:  \n",
    "      \n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "      return checked, word\n",
    "\n",
    "    return checked, word\n",
    "\n",
    "  # awalan diper-, keber-, keter-\n",
    "  if (word.startswith('diper') or word.startswith('keber') or word.startswith('keter')) and (len(word) > 5):\n",
    "    sub_word = word[5:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "    if checked==False:  \n",
    "\n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "      return checked, word\n",
    "    return checked, word\n",
    "\n",
    "  # awalan meng-, peng-\n",
    "  if (word.startswith('meng') or word.startswith('peng')) and (len(word) > 4):\n",
    "    sub_word = word[4:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "    if checked==False:  \n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "\n",
    "      if checked==False:  \n",
    "        # add 'k' in front word\n",
    "        sub_word = 'k' + word\n",
    "\n",
    "        # check word again in kamus\n",
    "        checked, word = kamus_word(sub_word)\n",
    "\n",
    "        if checked==False:  \n",
    "          # check word in derivation suffiks\n",
    "          checked, word_pref_suff_k = hapus_derivation_suffiks(word)\n",
    "\n",
    "          # check word again in kamus after add k in front\n",
    "          checked, word = kamus_word(word_pref_suff_k)\n",
    "          return checked, word\n",
    "        return checked, word\n",
    "      return checked, word\n",
    "    return checked, word\n",
    "\n",
    "  # awalan meny-, peny-\n",
    "  if (word.startswith('meny') or word.startswith('peny')) and (len(word) > 4):\n",
    "    sub_word = word[4:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "    if checked==False:  \n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "      if checked==False:  \n",
    "\n",
    "        # add 's' in front word\n",
    "        sub_word = 's' + word\n",
    "\n",
    "        # check word again in kamus\n",
    "        checked, word = kamus_word(sub_word)\n",
    "\n",
    "        if checked==False:  \n",
    "          # check word in derivation suffiks\n",
    "          checked, word_pref_suff_s = hapus_derivation_suffiks(word)\n",
    "\n",
    "          # check word again in kamus after add s in front\n",
    "          checked, word = kamus_word(word_pref_suff_s)\n",
    "        \n",
    "          return checked, word\n",
    "        return checked, word\n",
    "      return checked, word\n",
    "\n",
    "    return checked, word\n",
    "\n",
    "  # awalan mel-, mer-, pel-, per-\n",
    "  if (word.startswith('mel') or word.startswith('mer') or word.startswith('pel') or word.startswith('per')) and (len(word) > 3):\n",
    "    sub_word = word[3:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "\n",
    "    if checked==False:  \n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "\n",
    "      return checked, word\n",
    "    return checked, word\n",
    "\n",
    "  # awalan men-, pen-\n",
    "  if (word.startswith('men') or word.startswith('pen')) and (len(word) > 3):\n",
    "    sub_word = word[3:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "\n",
    "    if checked==False:  \n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "      sub_word = 't' + word_pref_suff\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(sub_word)\n",
    "      \n",
    "      if checked==False: \n",
    "        # check word in derivation suffiks\n",
    "        checked, word_pref_suff_t = hapus_derivation_suffiks(word)\n",
    "\n",
    "        # check word again in kamus after add s in front\n",
    "        checked, word = kamus_word(word_pref_suff_t)\n",
    "        return checked, word\n",
    "      return checked, word\n",
    "    return checked, word\n",
    "\n",
    "    \n",
    "  # awalan mem-, pem-\n",
    "  if (word.startswith('mem') or word.startswith('pem')) and (len(word) > 3):\n",
    "    sub_word = word[3:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "    \n",
    "    if checked==False:  \n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "      if checked==False:  \n",
    "        # add 's' in front word\n",
    "        sub_word = 'p' + word\n",
    "        \n",
    "        # check word again in kamus\n",
    "        checked, word = kamus_word(sub_word)\n",
    "        \n",
    "        \n",
    "        if checked==False:     \n",
    "          # check word in derivation suffiks\n",
    "          checked, word_pref_suff_p = hapus_derivation_suffiks(word)\n",
    "\n",
    "          # check word again in kamus after add s in front\n",
    "          checked, word = kamus_word(word_pref_suff_p)\n",
    "          return checked, word\n",
    "        return checked, word\n",
    "      return checked, word\n",
    "    return checked, word\n",
    "  \n",
    "  # awalan bel-, ber-, tel-, ter-\n",
    "  if (word.startswith('bel') or word.startswith('ber') or word.startswith('tel') or word.startswith('ter')) and (len(word) > 3):\n",
    "    sub_word = word[3:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "    if checked==False:  \n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "      return checked, word\n",
    "    return checked, word\n",
    "\n",
    "  # tipe awalan ke 1 : di-, ke-, se-\n",
    "  if (word.startswith('di') or word.startswith('ke') or word.startswith('se')) and (len(word) > 3):\n",
    "    sub_word = word[2:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "    if checked==False:\n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "      return checked, word\n",
    "    return checked, word\n",
    "\n",
    "\n",
    "  # tipe awalan ke 2 : be-, te-\n",
    "  if (word.startswith('be') or word.startswith('te')) and (len(word) > 2):\n",
    "    sub_word = word[2:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "    if checked==False:  \n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "      return checked, word\n",
    "\n",
    "    return checked, word\n",
    "\n",
    "  # tipe awalan ke 3 : me-, pe-\n",
    "  if (word.startswith('me') or word.startswith('pe')) and (len(word) > 2):\n",
    "    sub_word = word[2:]\n",
    "    # check if word exist in kamus\n",
    "    checked, word = kamus_word(sub_word)\n",
    "\n",
    "    if checked==False:  \n",
    "      # check word in derivation suffiks\n",
    "      checked, word_pref_suff = hapus_derivation_suffiks(word)\n",
    "\n",
    "      # check word again in kamus\n",
    "      checked, word = kamus_word(word_pref_suff)\n",
    "      return checked, word\n",
    "\n",
    "    return checked, word\n",
    "  return checked, word\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bustam', 'ketua', 'pwi', 'papua', 'barat', 'mengajak', 'para', 'wartawan', 'mendukung', 'program', 'pemerintah', 'mencegah', 'penyebaran', 'covid', '19', 'salah', 'satunya', 'dengan', 'mendapat', 'vaksinasi', '#otsuspapuaterbaik', 'pon', 'xx', 'papua', 'siap', 'httpstcojprb6kboux']\n",
      "['vaksinasi', 'diklaim', 'tingkatkan', 'jumlah', 'pengunjung', 'malioboro', 'httpstcogdt9otcswe', '#beritajogja', '#jogja', '#jogjaistimewa', 'httpstcofif4jxenim']\n",
      "['wujudkan', 'kekebalan', 'komunal', 'setelah', 'vaksinasi', 'dengan', 'mematuhi', '5m', 'memakai', 'masker', 'mencuci', 'tangan', 'menjaga', 'jarak', 'menjauhi', 'kerumunan', 'dan', 'membatasi', 'mobilitas', '', '@ronny_tri2000', '@divhumas_polri', '@poldajateng_', '', '#polriindonesia', '#polriuntukindonesia', '#kabarpemalang', '#inipemalang', 'httpstco8ttrt4dqur']\n",
      "['terima', 'kasih', 'kepada', 'pemerintah', 'atas', 'perhatiannya', 'sehingga', 'kalangan', 'difabel', 'mendapat', 'kesempatan', 'vaksinasi', 'dalam', 'waktu', 'yang', 'cepat', '', '#vaksinuntukkita']\n",
      "['nu', 'jatim', 'jangan', 'ikutin', 'hoaks', 'vaksin', 'sinovac', 'dan', 'astrazeneca', 'halal', '#mengenalvaksinastrazeneca', '#penerimavaksincovid19', '#edukasivaksincovid19', '#vaksin', '#vaksinasi', 'httpstcoxzcuslpdce', 'httpstcopdfsgmm7th']\n",
      "batas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_text = []\n",
    "for t in text.head():\n",
    "    t = t.lower()\n",
    "    t = tokenizing(t)\n",
    "    t = split_words(t)\n",
    "\n",
    "    list_text.append(t)\n",
    "    print(t)\n",
    "\n",
    "print('batas\\n')\n",
    "list_kamus = []\n",
    "for word in list_text:\n",
    "    words = []\n",
    "    for w in word:\n",
    "        # print(w)\n",
    "        # cek kamus pertama\n",
    "        checked,w = kamus_word(w)\n",
    "        if (checked):\n",
    "            words.append(w)\n",
    "            continue\n",
    "\n",
    "         # hapus derivation prefiks\n",
    "        checked,w = hapus_derivation_prefiks(w)\n",
    "        if checked:\n",
    "            words.append(w)\n",
    "            continue\n",
    "            \n",
    "        checked,w = hapus_infleksional_suffiks(w)\n",
    "        if checked:\n",
    "            words.append(w)\n",
    "            continue\n",
    "        \n",
    "        # hapus derivation suffiks\n",
    "        checked,w = hapus_derivation_suffiks(w)\n",
    "        if checked:\n",
    "            words.append(w)\n",
    "            continue\n",
    "\n",
    "        \n",
    "       \n",
    "    \n",
    "    list_kamus.append(' '.join(words))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ketua barat ajak para wartawan dukung program perintah cegah sebar salah satu dengan dapat vaksinasi siap', 'vaksinasi klaim tingkat jumlah unjung', 'wujud kebal komunal telah vaksinasi dengan patuh masker cuci tangan jaga jarak dan batas mobilitas', 'terima kasih kepada perintah atas hati sehingga difabel dapat sempat vaksinasi dalam waktu yang cepat', 'jangan vaksin dan halal']\n"
     ]
    }
   ],
   "source": [
    "print(list_kamus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_stemming = pd.DataFrame(list_kamus, columns=['Text_after_stemming'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_after_stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bagi kiat sukses vaksinasi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vaksinasi untuk umum kitar prioritas daerah pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vaksinasi untuk masyarakat umum ini akan prior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vaksinasi untuk umum kitar prioritas daerah pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vaksinasi untuk umum kitar prioritas daerah pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Text_after_stemming\n",
       "0                         bagi kiat sukses vaksinasi\n",
       "1  vaksinasi untuk umum kitar prioritas daerah pa...\n",
       "2  vaksinasi untuk masyarakat umum ini akan prior...\n",
       "3  vaksinasi untuk umum kitar prioritas daerah pa...\n",
       "4  vaksinasi untuk umum kitar prioritas daerah pa..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat data with Text_after_stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_text_stemming = data_copy.assign(Text_stemming=text_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>location</th>\n",
       "      <th>Text_stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-11 23:48:45+00:00</td>\n",
       "      <td>Sekda Aceh Berbagi Kiat Sukses Vaksinasi Covid...</td>\n",
       "      <td>Farder11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bagi kiat sukses vaksinasi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-11 23:47:54+00:00</td>\n",
       "      <td>Moeldoko: Vaksinasi Covid-19 untuk Umum Sekita...</td>\n",
       "      <td>zulitaufik</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>vaksinasi untuk umum kitar prioritas daerah pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-11 23:39:33+00:00</td>\n",
       "      <td>Vaksinasi untuk masyarakat umum ini akan mempr...</td>\n",
       "      <td>kompascom</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>vaksinasi untuk masyarakat umum ini akan prior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-11 23:30:02+00:00</td>\n",
       "      <td>Moeldoko: Vaksinasi Covid-19 untuk Umum Sekita...</td>\n",
       "      <td>aldotjahjadi8</td>\n",
       "      <td>ihsgjournal@gmail.com</td>\n",
       "      <td>vaksinasi untuk umum kitar prioritas daerah pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-11 23:23:31+00:00</td>\n",
       "      <td>Moeldoko: Vaksinasi Covid-19 untuk Umum Sekita...</td>\n",
       "      <td>cosmofemalefm</td>\n",
       "      <td>Kota Manado, Sulawesi Utara</td>\n",
       "      <td>vaksinasi untuk umum kitar prioritas daerah pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-02-11 23:02:20+00:00</td>\n",
       "      <td>#BuletinBernama: Vaksinasi COVID-19 bermula Ma...</td>\n",
       "      <td>BernamaTV</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-02-11 23:02:15+00:00</td>\n",
       "      <td>Vaksinasi bagi para lansia untuk memperkuat im...</td>\n",
       "      <td>hasimramadan02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-11 23:00:25+00:00</td>\n",
       "      <td>Dengarkan bicara vaksin COVID-19 &amp;amp; kepenti...</td>\n",
       "      <td>JKJAVMY</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-02-11 22:41:38+00:00</td>\n",
       "      <td>Sebagai Saran buat Bapak Menteri Desa PDTT , d...</td>\n",
       "      <td>IsidorusArwan3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-02-11 22:20:39+00:00</td>\n",
       "      <td>Kapolsek Baturetno AKP DIYATNO, SH beserta Dan...</td>\n",
       "      <td>kota_sate</td>\n",
       "      <td>Baturetno, Wonogiri, Indonesia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime  \\\n",
       "0  2021-02-11 23:48:45+00:00   \n",
       "1  2021-02-11 23:47:54+00:00   \n",
       "2  2021-02-11 23:39:33+00:00   \n",
       "3  2021-02-11 23:30:02+00:00   \n",
       "4  2021-02-11 23:23:31+00:00   \n",
       "5  2021-02-11 23:02:20+00:00   \n",
       "6  2021-02-11 23:02:15+00:00   \n",
       "7  2021-02-11 23:00:25+00:00   \n",
       "8  2021-02-11 22:41:38+00:00   \n",
       "9  2021-02-11 22:20:39+00:00   \n",
       "\n",
       "                                                Text        Username  \\\n",
       "0  Sekda Aceh Berbagi Kiat Sukses Vaksinasi Covid...        Farder11   \n",
       "1  Moeldoko: Vaksinasi Covid-19 untuk Umum Sekita...      zulitaufik   \n",
       "2  Vaksinasi untuk masyarakat umum ini akan mempr...       kompascom   \n",
       "3  Moeldoko: Vaksinasi Covid-19 untuk Umum Sekita...   aldotjahjadi8   \n",
       "4  Moeldoko: Vaksinasi Covid-19 untuk Umum Sekita...   cosmofemalefm   \n",
       "5  #BuletinBernama: Vaksinasi COVID-19 bermula Ma...       BernamaTV   \n",
       "6  Vaksinasi bagi para lansia untuk memperkuat im...  hasimramadan02   \n",
       "7  Dengarkan bicara vaksin COVID-19 &amp; kepenti...         JKJAVMY   \n",
       "8  Sebagai Saran buat Bapak Menteri Desa PDTT , d...  IsidorusArwan3   \n",
       "9  Kapolsek Baturetno AKP DIYATNO, SH beserta Dan...       kota_sate   \n",
       "\n",
       "                         location  \\\n",
       "0                             NaN   \n",
       "1                         Jakarta   \n",
       "2                         Jakarta   \n",
       "3           ihsgjournal@gmail.com   \n",
       "4     Kota Manado, Sulawesi Utara   \n",
       "5                    Kuala Lumpur   \n",
       "6                             NaN   \n",
       "7                        Malaysia   \n",
       "8                             NaN   \n",
       "9  Baturetno, Wonogiri, Indonesia   \n",
       "\n",
       "                                       Text_stemming  \n",
       "0                         bagi kiat sukses vaksinasi  \n",
       "1  vaksinasi untuk umum kitar prioritas daerah pa...  \n",
       "2  vaksinasi untuk masyarakat umum ini akan prior...  \n",
       "3  vaksinasi untuk umum kitar prioritas daerah pa...  \n",
       "4  vaksinasi untuk umum kitar prioritas daerah pa...  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_text_stemming.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = data_with_text_stemming.to_csv('../../data/data_2_stemming.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_neg = pd.read_csv('../components/InSet-master/negative.tsv', sep=\"\\t\")\n",
    "lexicon_pos = pd.read_csv('../components/InSet-master/positive.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>putus tali gantung</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gelebah</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gobar hati</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tersentuh (perasaan)</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>isak</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word  weight\n",
       "0    putus tali gantung      -2\n",
       "1               gelebah      -2\n",
       "2            gobar hati      -2\n",
       "3  tersentuh (perasaan)      -1\n",
       "4                  isak      -5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hai</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>merekam</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ekstensif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paripurna</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  weight\n",
       "0        hai       3\n",
       "1    merekam       2\n",
       "2  ekstensif       3\n",
       "3  paripurna       1\n",
       "4     detail       2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = text_stemming['Text_after_stemming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = split_words(test_text[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bagi', 'kiat', 'sukses', 'vaksinasi']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = 0\n",
    "for w in split:\n",
    "    for ind in lexicon_neg.index:\n",
    "        # print(lexicon_neg['word'][ind], lexicon_neg['weight'][ind])\n",
    "\n",
    "        if lexicon_neg['word'][ind] == w :\n",
    "            neg += lexicon_neg['weight'][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0\n",
    "for w in split:\n",
    "    for ind in lexicon_pos.index:\n",
    "        # print(lexicon_neg['word'][ind], lexicon_neg['weight'][ind])\n",
    "\n",
    "        if lexicon_pos['word'][ind] == w :\n",
    "            pos += lexicon_pos['weight'][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (4185179895.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [29], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "\n",
    "for w in split:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('ENV-mining': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e120dd08cc27d548b9636efe50e3bf60d9e88050f9a29808f06571a6a719f4da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
